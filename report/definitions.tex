\chapter{Nomenclature}\label{cha:def}

p. ~710 at \citep{norvigAI}

\begin{description}
    \item[Learning] Improved performance on future tasks after making observations about the world.

    \item[Unsupervised learning] Explained in theory.

    \item[Supervised learning] Explained in theory.

    \item[Clustering] Groups related users and items together to produce a set of clusters. A form of unsupervised learning. \Warning[TODO]{ Ref }
Explain this in theory!

    \item[Curse of dimensionality]
\end{description}

\vspace{2cm}

\begin{description}
    \item[recommendations]
    \item[e-commerce]
    \item[true positives]
    \item[false positives]
    \item[false negatives]
    \item[Precision]
    \item[Recall]
    \item[F-measure]
    \item[ratings]
    \item[interaction history]
    \item[interaction count]
    \item[machine learning]
    \item[implicit feedback]
    \item[explicit feedback]
    \item[overfitting]
\end{description}

Suggested by netflix post

\begin{description}
    \item[Linear regression]
    \item[Logistic regression]
    \item[Elastic nets]
    \item[Singular Value Decomposition]
    \item[Restricted Boltzmann Machines]
    \item[Markov Chains]
    \item[Latent Dirichlet Allocation]
    \item[Association Rules]
    \item[Gradient Boosted Decision Trees]
    \item[Random Forests]
    \item[Clustering techniques] \hfill
        From the simple k-means to novel graphical approaches such as Affinity Propagation
    \item[Matrix factorization]
\end{description}

