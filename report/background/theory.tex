
\section{Theory}\label{sec:theory}

This section introduces the mathematical theory behind the recommendation model, a summary of the supervised learning process and some theory about the evaluation metrics \textit{Precision}, \textit{Recall} and \textit{F-measure}. Then a brief overview of optimization techniques is given and then explanation of the recommendation algorithms \textit{link-analysis} and \textit{katz-eig}. The section is finished by a brief mention of unsupervised learning techniques, mainly about clustering.

This is the basic process of producing recommendations:

\begin{enumerate}
    \item Given an interaction history $h_{u, i}$, $u \in Users$, $i \in Items$ and algorithm specific parameters the recommendation algorithm produce recommendations $p_{u, i}$.
        %\\
        %$p_{u, i} = 0$ whenever $h_{u, i} = 1 \; \forall \,u, i$ so no items are recommended if interactions have already been made.
    \item The recommendations $p_{u, i}$, which are real values, are converted to binary recommendations $r_{u, i}$ by selecting the $N$ largest $p_{u, i}$ as $r_{u, i} = 1$.
\end{enumerate}

The process of parameter tuning used is as follows:

\begin{enumerate}
    \item Split the interaction matrix $A$ into a training set $A_{train}$, a validation set $A_{val}$ and a test set $A_{test}$.
    \item Evaluate different parameters by producing recommendations with $A_{train}$ and evaluating them against $A_{val}$ or $A_{test}$ with respect to \textit{F-measure}.
    \item Select the best performing parameters with respect to \textit{F-measure}.
\end{enumerate}

\input{background/theory/model.tex}
\input{background/theory/prediction.tex}
\input{background/theory/suplearn.tex}
\input{background/theory/evaluation.tex}
\input{background/theory/opt.tex}

\input{background/theory/linkanalysis.tex}
\input{background/theory/katzeig.tex}

\input{background/theory/unsuplearn.tex}

