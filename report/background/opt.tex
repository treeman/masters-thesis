
\section{Optimization}\label{sec:background:opt}

Most supervised learning algorithms try to minimize a cost function during the learning phase. This function computes a value given some learned parameters and it can vary with different algorithms. The cost function does not make a comparison between two different sets but computes a metric from a single set.

A simple cost function (without regularization) could be defined as

\begin{equation}
    \min_{r_{u, i}} \sum_{h_{u,i} \text{ is known} } (h_{u, i} - r_{u, i})^2
\end{equation}

A typical recommendation model associates each user $u$ with a user-factors vector $x_u$ and each item $i$ with an item-factors vector $y_i$ such that $r_{u, i} = x_u^T y_i$
\citep{hu2008collaborative}. In such a case a cost function could be defined as

\begin{equation}
    \min_{x_*, y_*} \sum_{h_{u,i} \text{ is known} } (h_{u, i} - x_{u}^T y_i)^2
\end{equation}

where the the optimization objective is $x_u$ and $y_i$. Usually stochastic gradient descent is used to find the parameters \cite{hu2008collaborative}. With regularization a possible cost function could be

\begin{equation}\label{eq:exreg}
    \min_{x_*, y_*} \sum_{h_{u,i} \text{ is known} } (h_{u, i} - x_{u}^T y_i)^2 + \lambda(\|x_u\|^2 + \|y_i\|^2)
\end{equation}

where $\lambda$ is the regularization hyperparameter found using \textit{model selection}. This directly penalizes larger values of $x_u$ and $y_i$ which in this case corresponds to an increase in complexity.

Metrics such as \textit{F-measure} can be used directly as optimization criteria if a suitable cost function is hard to find. It is also a common way of evaluating different models during model selection, the hyperparameter $\lambda$ in equation \eqref{eq:exreg} can be evaluated in this way
\footnote{Machine Learning, Stanford. \url{https://class.coursera.org/ml-006}}
.

There are a couple of generic optimization techniques used for optimizing cost functions and selecting parameters via recommender quality metrics such as \textit{F-measure}. In all cases the problem consists of minimizing or maximizing a target function. What follows are short descriptions of some common techniques:


\subsubsection{Grid search}

Grid search is a straightforward search technique which evaluates the function over a limited parameter space. This is a recommended approach for selecting the regularization parameter $\lambda$
\footnote{Suggested by Andrew Ng in his lectures on Machine Learning. \url{https://class.coursera.org/ml-006}}.

Grid search is easily parallelized but it suffers from the curse of dimensionality, where it's particularly slow if used to optimize multiple parameters.


\subsubsection{Random search}

Grid search is exhaustive and possibly expensive, random search with a fixed limit of samples has been shown to be more effective in high-dimension spaces \citep{bergstra2012random}. Random search is easily parallelized but lacks guidance.


\subsubsection{Hill climbing}

Is a technique for finding a local optima from a given starting point. The neighbours of the current state is examined and the state is moved to the neighbour with a better function value until a local optima has been found. Variations for continuous functions exists which decrease the step size dynamically to increase the precision. \citep{norvigAI}


\subsubsection{Gradient based approaches}

Variations of gradient based optimization techniques such as stochastic gradient descent can be used to optimize functions given that a gradient can be found. The search is similar to that of hill climbing, but is guided by the gradient and optimizes for a local optima.  This is a fast and popular method for optimizing learning parameters.
\cite{hu2008collaborative}


\subsubsection{Simulated annealing}

Simulated annealing is a probabilistic heuristic optimization technique used for finding global optima in a limited search space. It works by randomly jumping to neighbouring points with decreasing probability until it converges on a local optima. However it is more likely to find a better local optima than a gradient based approach. \citep{norvigAI}


\subsubsection{Bayesian optimization}

Bayesian optimization develops a statistical model over the function space and evaluates the function sparsely which balances exploration and exploitation.  With \textit{Gaussian process priors}, a form of statistical modeling of a function, Bayesian optimization has been shown to give better results with fewer evaluations than grid search. \citep{snoek2012practical}

