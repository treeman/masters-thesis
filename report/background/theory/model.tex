
\subsection{Model}\label{sec:background:theory:model}

Given a set of users $U$, a set of items $I$ and an interaction history $h_{u, i}$ given in \textit{unweighted binary form}

\begin{equation}\label{eq:hist}
    h_{u, i} = \begin{cases}
        1 \quad \text{if user $u$ has interacted with item $i$} \\
        0 \quad \text{otherwise}
    \end{cases}
\end{equation}

the \textit{recommender problem} is defined by producing a set of recommendations $r_{u, i}$

\begin{equation}
    r_{u, i} = \begin{cases}
        1 \quad \text{if item $i$ is recommended to user $u$} \\
        0 \quad \text{otherwise}
    \end{cases}
\end{equation}

to maximize the probability that user $u$ will want to interact with item $i$ in the future, for all users and items.  This definition is applicable for \textit{implicit feedback} systems which passively track different sorts of user behaviour. For example link following, interaction time and purchase history.

The recommender problem can be extended to the \textit{Top-N recommender problem} by introducing constraints \eqref{eq:constrain_N} which states that only $N$ recommendations can be presented for each user.

\begin{equation}\label{eq:constrain_N}
    \sum_i r_{u, i} \leq N \quad \forall u
\end{equation}


A variation of the recommender problem is when the interaction history is in \textit{weighted form}, when the values increase with each interaction

\begin{equation}\label{eq:whist}
    h_{u, i} = \begin{cases}
        x \quad \text{user $u$ has interacted $x$ times with item $i$} \\
        0 \quad \text{otherwise}
    \end{cases}
\end{equation}

for example $h_{u, i} = 2$ means that the user $u$ has interacted with item $i$ 2 times. It is possible to allow \textit{implicit feedback} systems to log partial interactions, so $h_{u, i} = 0.7$ could mean that user $u$ has watched 70\% of the movie $i$, in the context of movie watching. \citep{hu2008collaborative}

The converse of \textit{implicit feedback} is \textit{explicit feedback} where the users give direct input regarding their preferences, for example with movie ratings or with likes and dislikes.  Here the definition of the interaction history $h_{u, i}$ is the users' rating history.

\begin{equation}
    h_{u, i} = \begin{cases}
        R \quad \text{the rating $R$ user $u$ gave item $i$} \\
        \emptyset \quad \text{if the user $u$ did not rate item $i$}
    \end{cases}
\end{equation}

\Warning[TODO]{ Uses h for all equations? }

The algorithms which produce recommendations produce predictions for each user-item pair, denoted $p_{u, i}$. For interaction history in unweighted binary form if $p_{u, i}$ is close to 1 it means item $i$ is predicted with high probability to user $u$ and a value close to 0 means it's not predicted. If the interaction history instead describes ratings the value corresponds to the predicted ratings the users would give, for example $p_{u, i} = 3.8$ means the algorithm is predicting user $u$ to rate item $i$ a 4, given ratings between 1 and 5.
\Warning[TODO]{ Move to own theory? }

To produce top-N recommendations take the $N$ largest values of $p_{u, i}$ for each user. If it's important to recognize non-recommendations it is possible to set $r_{u, i} = 0$ if $p_{u, i} \leq \epsilon$, for some $\epsilon$, to accommodate for fewer than $N$ recommendations.

This thesis will use an interaction history given in unweighted binary form and will produce recommendations for the Top-N recommender problem.
\Warning[TODO]{ Move to own theory? }

To transform datasets with the more common explicit feedback style of ratings to an unweighted binary form a crude model \eqref{eq:rating2binary} will be used.
\Warning[TODO]{ Move to my own theory?}

\begin{equation} \label{eq:rating2binary}
    h_{u, i} = \begin{cases}
        1 \quad \text{user $u$ has rated item $i$} \\
        0 \quad \text{otherwise}
    \end{cases}
\end{equation}

