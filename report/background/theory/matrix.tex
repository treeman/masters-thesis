
\subsection{Matrix representation}\label{sec:background:theory:matrix}

It is sometimes notationally convenient to see the interaction history along with the training, validation and test set as matrices.

The whole interaction history, $h_{u, i}$ will in matrix form be denoted by the interaction matrix $A = (h_{u, i})$, with each row representing each user and each column representing each item.

For example given an interaction matrix

\begin{equation}
    A =
    \begin{pmatrix}
        1 & 0 & 1 & 0 \\
        0 & 0 & 1 & 1 \\
    \end{pmatrix}
\end{equation}

with 2 users and 4 items, has the interaction history: $h_{1, 1} = 1$, $h_{1, 3} = 1$, $h_{2, 3} = 1$ and $h_{2, 4} = 1$.

The training, validation and test set matrices will be denoted $A_{train}$, $A_{val}$ and $A_{test}$ respectively. Their elements are pairwise disjoint, so no non-zero elements will be shared by the matrices.

The recommendation set $r_{u, i}$ will be represented by the recommendation matrix $R = (r_{u, i})$ and the predictions $p_{u, i}$ by the prediction matrix $P = (p_{u, i})$.

Implementation wise the matrices are often stored in a sparse format which only stores nonzero elements in memory. This can significantly speed up both computations and storage usage, depending on the sparsity of the matrix. The sparse format lends itself very well for interaction history in unweighted binary form as the uninterested interactions are modeled as zero elements in the matrix.

